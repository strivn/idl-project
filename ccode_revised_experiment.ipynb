{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from transformers import GPTNeoXForCausalLM, AutoTokenizer\n",
    "from datasets import load_dataset, Dataset\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from rouge_score import rouge_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/ivw/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /Users/ivw/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download necessary NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models\n",
    "def load_models(device='cpu'):\n",
    "    # Forward model\n",
    "    fo_model = GPTNeoXForCausalLM.from_pretrained(\n",
    "        \"EleutherAI/pythia-160m-deduped\",\n",
    "        revision=\"step143000\",\n",
    "        cache_dir=\"./.cache/pythia-160m-deduped/step143000\",\n",
    "    ).to(device)\n",
    "    \n",
    "    fo_tokenizer = AutoTokenizer.from_pretrained(\n",
    "        \"EleutherAI/pythia-160m-deduped\",\n",
    "        revision=\"step143000\",\n",
    "        cache_dir=\"./.cache/pythia-160m-deduped/step143000\",\n",
    "    )\n",
    "    \n",
    "    # Backward model\n",
    "    ba_model = GPTNeoXForCausalLM.from_pretrained(\n",
    "        \"afterless/reverse-pythia-160m\",\n",
    "        cache_dir=\"./.cache/reverse-pythia-160m\",\n",
    "    ).to(device)\n",
    "    \n",
    "    ba_tokenizer = AutoTokenizer.from_pretrained(\n",
    "        \"afterless/reverse-pythia-160m\",\n",
    "        cache_dir=\"./.cache/reverse-pythia-160m\",\n",
    "    )\n",
    "    \n",
    "    return fo_model, fo_tokenizer, ba_model, ba_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "def load_cnn_dataset(num_samples=10):\n",
    "    try:\n",
    "        # Try with a specific cache directory\n",
    "        dataset = load_dataset(\"cnn_dailymail\", \"3.0.0\", cache_dir=\".cache\")\n",
    "        print(\"Dataset loaded successfully\")\n",
    "        \n",
    "        # Verify the structure - this helps debug\n",
    "        if num_samples > 0:\n",
    "            print(\"Example dataset item:\", dataset['train'][0])\n",
    "            \n",
    "        # Take only a small sample for testing\n",
    "        if hasattr(dataset, 'train'):\n",
    "            return dataset['train'].select(range(min(num_samples, len(dataset['train']))))\n",
    "        \n",
    "        return dataset['train'][:num_samples]\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading full dataset: {e}\")\n",
    "        \n",
    "        # Create a tiny synthetic dataset for testing\n",
    "        print(\"Creating synthetic test dataset instead...\")\n",
    "        \n",
    "        sample_data = {\n",
    "            'article': [\n",
    "                \"John likes to play basketball. He goes to the court every evening. His friends join him on weekends.\",\n",
    "                \"The company announced record profits. Investors were pleased. The stock price increased by 10%.\"\n",
    "            ],\n",
    "            'highlights': [\n",
    "                \"John plays basketball regularly with friends.\",\n",
    "                \"Company profits lead to stock price increase.\"\n",
    "            ],\n",
    "            'id': ['test1', 'test2']  # Added ID field\n",
    "        }\n",
    "        \n",
    "        return Dataset.from_dict(sample_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(example):\n",
    "    \"\"\"\n",
    "    Process the CNN dataset example to extract article and highlight sentences\n",
    "    \"\"\"\n",
    "    # Handle the article - could be a string or a list\n",
    "    if isinstance(example['article'], list):\n",
    "        # Already in list format\n",
    "        article_sentences = example['article']\n",
    "    else:\n",
    "        # Need to tokenize\n",
    "        article_sentences = nltk.sent_tokenize(example['article'])\n",
    "    \n",
    "    # Handle the highlights - could be a string or a list\n",
    "    if isinstance(example['highlights'], list):\n",
    "        # Already in list format\n",
    "        highlight_sentences = example['highlights']\n",
    "    else:\n",
    "        # Need to tokenize\n",
    "        highlight_sentences = nltk.sent_tokenize(example['highlights'])\n",
    "    \n",
    "    return {\n",
    "        'article_sentences': article_sentences,\n",
    "        'highlight_sentences': highlight_sentences\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_baseline_score(model, tokenizer, article_sentence, highlight, device='cpu'):\n",
    "    \"\"\"Compute P(highlight|article_sentence)\"\"\"\n",
    "    # Format: [article_sentence] is summarized by: [highlight]\n",
    "    input_text = f\"{article_sentence} is summarized by: \"\n",
    "    \n",
    "    # Tokenize the input and target separately\n",
    "    input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(device)\n",
    "    target_ids = tokenizer(highlight, return_tensors=\"pt\").input_ids.to(device)\n",
    "    \n",
    "    # Concatenate for full sequence, but remember where the split is\n",
    "    full_ids = t.cat([input_ids, target_ids[:, 1:]], dim=1)  # Skip BOS token for target\n",
    "    \n",
    "    # Setup for loss calculation - we only want loss on highlight tokens\n",
    "    labels = t.full_like(full_ids, -100)  # -100 is ignored in loss calculation\n",
    "    labels[:, input_ids.shape[1]:] = target_ids[:, 1:]  # Only compute loss on highlight\n",
    "    \n",
    "    # Calculate loss\n",
    "    outputs = model(full_ids, labels=labels)\n",
    "    return outputs.loss.item()\n",
    "\n",
    "def trlm_fo_score(model, tokenizer, article_sentence, highlight, device='cpu'):\n",
    "    \"\"\"Compute P(article_sentence|highlight)\"\"\"\n",
    "    # Format: [article_sentence] is a summary of: [highlight]\n",
    "    input_text = f\"{highlight} is a summary of: \"\n",
    "    \n",
    "    # Tokenize the input and target separately\n",
    "    input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(device)\n",
    "    target_ids = tokenizer(article_sentence, return_tensors=\"pt\").input_ids.to(device)\n",
    "    \n",
    "    # Concatenate for full sequence\n",
    "    full_ids = t.cat([input_ids, target_ids[:, 1:]], dim=1)\n",
    "    \n",
    "    # Setup for loss calculation - we only want loss on article sentence tokens\n",
    "    labels = t.full_like(full_ids, -100)\n",
    "    labels[:, input_ids.shape[1]:] = target_ids[:, 1:]\n",
    "    \n",
    "    # Calculate loss\n",
    "    outputs = model(full_ids, labels=labels)\n",
    "    return outputs.loss.item()\n",
    "\n",
    "def trlm_ba_score(backward_model, backward_tokenizer, article_sentence, highlight, device='cpu'):\n",
    "    \"\"\"Compute P(article_sentence|highlight) using backward model\"\"\"\n",
    "    # Format according to paper: [highlight] is summarized by: [article_sentence]\n",
    "    \n",
    "    # We need to tokenize each part separately to know token boundaries\n",
    "    highlight_tokens = backward_tokenizer(highlight, return_tensors=\"pt\").input_ids.to(device)\n",
    "    connector_tokens = backward_tokenizer(\" is summarized by: \", return_tensors=\"pt\").input_ids.to(device)\n",
    "    article_tokens = backward_tokenizer(article_sentence, return_tensors=\"pt\").input_ids.to(device)\n",
    "    \n",
    "    # Combine all tokens (removing extra BOS tokens if needed)\n",
    "    # Keep only first BOS token, remove others\n",
    "    if connector_tokens.size(1) > 1:\n",
    "        connector_tokens = connector_tokens[:, 1:]\n",
    "    if article_tokens.size(1) > 1:\n",
    "        article_tokens = article_tokens[:, 1:]\n",
    "    \n",
    "    combined_tokens = t.cat([highlight_tokens, connector_tokens, article_tokens], dim=1)\n",
    "    \n",
    "    # Now reverse the combined tokens\n",
    "    reversed_tokens = t.flip(combined_tokens, dims=[1])\n",
    "    \n",
    "    # Create labels tensor - start with all -100 (ignored positions)\n",
    "    labels = t.full_like(reversed_tokens, -100)\n",
    "    \n",
    "    # In the reversed sequence, the article tokens appear at the beginning\n",
    "    # The length of article_tokens tells us how many tokens to score\n",
    "    article_length = article_tokens.size(1)\n",
    "    \n",
    "    # Set the labels for article tokens (now at the beginning of reversed sequence)\n",
    "    labels[:, :article_length] = reversed_tokens[:, :article_length]\n",
    "    \n",
    "    # Calculate loss only on the article tokens\n",
    "    outputs = backward_model(reversed_tokens, labels=labels)\n",
    "    return outputs.loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(predicted_sentence, gold_sentences):\n",
    "    \"\"\"\n",
    "    Calculate similarity metrics between predicted sentence and gold references\n",
    "    \"\"\"\n",
    "    try:\n",
    "        nltk.data.find('tokenizers/punkt')\n",
    "    except LookupError:\n",
    "        nltk.download('punkt')\n",
    "    \n",
    "    # Handle empty inputs\n",
    "    if not predicted_sentence or not gold_sentences:\n",
    "        return {\n",
    "            'tfidf_similarity': 0,\n",
    "            'embedding_similarity': 0,\n",
    "            'rouge1': 0,\n",
    "            'rougeL': 0,\n",
    "            'bleu': 0\n",
    "        }\n",
    "    \n",
    "    # Load a sentence embedding model\n",
    "    sentence_model = SentenceTransformer('all-mpnet-base-v2')\n",
    "    \n",
    "    # TF-IDF similarity\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    try:\n",
    "        tfidf_matrix = vectorizer.fit_transform([predicted_sentence] + gold_sentences)\n",
    "        tfidf_similarities = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:])[0]\n",
    "        tfidf_score = max(tfidf_similarities) if len(tfidf_similarities) > 0 else 0\n",
    "    except:\n",
    "        tfidf_score = 0\n",
    "    \n",
    "    # Embedding similarity\n",
    "    try:\n",
    "        pred_embedding = sentence_model.encode(predicted_sentence)\n",
    "        gold_embeddings = sentence_model.encode(gold_sentences)\n",
    "        embedding_similarities = cosine_similarity([pred_embedding], gold_embeddings)[0]\n",
    "        embedding_score = max(embedding_similarities) if len(embedding_similarities) > 0 else 0\n",
    "    except:\n",
    "        embedding_score = 0\n",
    "    \n",
    "    # ROUGE score\n",
    "    try:\n",
    "        scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n",
    "        rouge_scores = [scorer.score(predicted_sentence, gold_sent) for gold_sent in gold_sentences]\n",
    "        rouge1_score = max([score['rouge1'].fmeasure for score in rouge_scores]) if rouge_scores else 0\n",
    "        rougeL_score = max([score['rougeL'].fmeasure for score in rouge_scores]) if rouge_scores else 0\n",
    "    except:\n",
    "        rouge1_score = 0\n",
    "        rougeL_score = 0\n",
    "    \n",
    "    # BLEU score with smoothing to avoid zero scores\n",
    "    try:\n",
    "        # Tokenize for BLEU calculation\n",
    "        predicted_tokens = nltk.word_tokenize(predicted_sentence.lower())\n",
    "        gold_tokens = [nltk.word_tokenize(gold.lower()) for gold in gold_sentences]\n",
    "        \n",
    "        # Use smoothing function to mitigate \"0 counts of n-gram overlaps\" warnings\n",
    "        smoother = SmoothingFunction().method1\n",
    "        \n",
    "        # Calculate BLEU score - take the best score against any reference\n",
    "        bleu_scores = [\n",
    "            sentence_bleu([gold_tok], predicted_tokens, \n",
    "                         weights=(0.25, 0.25, 0.25, 0.25),\n",
    "                         smoothing_function=smoother)\n",
    "            for gold_tok in gold_tokens\n",
    "        ]\n",
    "        bleu_score = max(bleu_scores) if bleu_scores else 0\n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating BLEU: {e}\")\n",
    "        bleu_score = 0\n",
    "    \n",
    "    return {\n",
    "        'tfidf_similarity': tfidf_score,\n",
    "        'embedding_similarity': embedding_score,\n",
    "        'rouge1': rouge1_score,\n",
    "        'rougeL': rougeL_score,\n",
    "        'bleu': bleu_score\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def calculate_model_scores(fo_model, fo_tokenizer, ba_model, ba_tokenizer, \n",
    "#                           article_sentences, highlight, device='cpu'):\n",
    "#     \"\"\"\n",
    "#     Calculate scores for both forward and backward models properly.\n",
    "#     Returns scores and selected sentences.\n",
    "#     \"\"\"\n",
    "#     # Forward baseline scoring: P(highlight|sentence)\n",
    "#     fw_scores = []\n",
    "#     for sentence in article_sentences:\n",
    "#         # Condition = sentence, Target = highlight\n",
    "#         condition = f\"{sentence} is summarized by: \"\n",
    "        \n",
    "#         # Tokenize condition and target separately\n",
    "#         condition_ids = fo_tokenizer(condition, return_tensors=\"pt\").input_ids.to(device)\n",
    "#         target_ids = fo_tokenizer(highlight, return_tensors=\"pt\").input_ids.to(device)\n",
    "        \n",
    "#         # Combine them (skipping BOS token in target)\n",
    "#         input_ids = t.cat([condition_ids, target_ids[:, 1:] if target_ids.size(1) > 1 else target_ids], dim=1)\n",
    "        \n",
    "#         # Create label mask that only calculates loss on target tokens\n",
    "#         labels = t.full_like(input_ids, -100)\n",
    "#         labels[:, condition_ids.size(1):] = input_ids[:, condition_ids.size(1):]\n",
    "        \n",
    "#         # Calculate loss\n",
    "#         with t.no_grad():\n",
    "#             outputs = fo_model(input_ids.to(device), labels=labels.to(device))\n",
    "#             fw_scores.append(outputs.loss.item())\n",
    "    \n",
    "#     # TRLM-Fo scoring: P(sentence|highlight)\n",
    "#     trlm_fo_scores = []\n",
    "#     for sentence in article_sentences:\n",
    "#         # Condition = highlight, Target = sentence\n",
    "#         condition = f\"{highlight} is a summary of: \"\n",
    "        \n",
    "#         # Tokenize condition and target separately\n",
    "#         condition_ids = fo_tokenizer(condition, return_tensors=\"pt\").input_ids.to(device)\n",
    "#         target_ids = fo_tokenizer(sentence, return_tensors=\"pt\").input_ids.to(device)\n",
    "        \n",
    "#         # Combine them\n",
    "#         input_ids = t.cat([condition_ids, target_ids[:, 1:] if target_ids.size(1) > 1 else target_ids], dim=1)\n",
    "        \n",
    "#         # Create label mask\n",
    "#         labels = t.full_like(input_ids, -100)\n",
    "#         labels[:, condition_ids.size(1):] = input_ids[:, condition_ids.size(1):]\n",
    "        \n",
    "#         # Calculate loss\n",
    "#         with t.no_grad():\n",
    "#             outputs = fo_model(input_ids.to(device), labels=labels.to(device))\n",
    "#             trlm_fo_scores.append(outputs.loss.item())\n",
    "    \n",
    "#     # TRLM-Ba scoring (using backward model)\n",
    "#     trlm_ba_scores = []\n",
    "#     for sentence in article_sentences:\n",
    "#         # Format text according to TRLM-Ba\n",
    "#         text = f\"{highlight} is summarized by: {sentence}\"\n",
    "        \n",
    "#         # Tokenize and reverse\n",
    "#         tokens = ba_tokenizer(text, return_tensors=\"pt\").input_ids.to(device)\n",
    "#         reversed_tokens = t.flip(tokens, dims=[1])\n",
    "        \n",
    "#         # We would need a more sophisticated approach to properly mask the labels\n",
    "#         # For simplicity, we'll use the full sequence loss here\n",
    "#         with t.no_grad():\n",
    "#             outputs = ba_model(reversed_tokens, labels=reversed_tokens)\n",
    "#             trlm_ba_scores.append(outputs.loss.item())\n",
    "    \n",
    "#     # Find best match for each model\n",
    "#     fw_best_idx = np.argmin(fw_scores)\n",
    "#     trlm_fo_best_idx = np.argmin(trlm_fo_scores)\n",
    "#     trlm_ba_best_idx = np.argmin(trlm_ba_scores)\n",
    "    \n",
    "#     return {\n",
    "#         'forward': {\n",
    "#             'scores': fw_scores,\n",
    "#             'best_sentence': article_sentences[fw_best_idx],\n",
    "#             'best_score': fw_scores[fw_best_idx]\n",
    "#         },\n",
    "#         'trlm_fo': {\n",
    "#             'scores': trlm_fo_scores,\n",
    "#             'best_sentence': article_sentences[trlm_fo_best_idx],\n",
    "#             'best_score': trlm_fo_scores[trlm_fo_best_idx]\n",
    "#         },\n",
    "#         'trlm_ba': {\n",
    "#             'scores': trlm_ba_scores,\n",
    "#             'best_sentence': article_sentences[trlm_ba_best_idx],\n",
    "#             'best_score': trlm_ba_scores[trlm_ba_best_idx]\n",
    "#         }\n",
    "#     }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_model_scores(fo_model, fo_tokenizer, ba_model, ba_tokenizer, \n",
    "                          article_sentences, highlight, device='cpu'):\n",
    "    \"\"\"\n",
    "    Calculate scores for all models and return the best matching sentences.\n",
    "    \"\"\"\n",
    "    # Calculate scores for each model\n",
    "    fw_scores = [forward_baseline_score(fo_model, fo_tokenizer, sentence, highlight, device) \n",
    "                for sentence in article_sentences]\n",
    "    \n",
    "    trlm_fo_scores = [trlm_fo_score(fo_model, fo_tokenizer, sentence, highlight, device) \n",
    "                     for sentence in article_sentences]\n",
    "    \n",
    "    trlm_ba_scores = [trlm_ba_score(ba_model, ba_tokenizer, sentence, highlight, device) \n",
    "                     for sentence in article_sentences]\n",
    "    \n",
    "    # Find best match for each model\n",
    "    fw_best_idx = np.argmin(fw_scores)\n",
    "    trlm_fo_best_idx = np.argmin(trlm_fo_scores)\n",
    "    trlm_ba_best_idx = np.argmin(trlm_ba_scores)\n",
    "    \n",
    "    return {\n",
    "        'forward': {\n",
    "            'scores': fw_scores,\n",
    "            'best_sentence': article_sentences[fw_best_idx],\n",
    "            'best_score': fw_scores[fw_best_idx]\n",
    "        },\n",
    "        'trlm_fo': {\n",
    "            'scores': trlm_fo_scores,\n",
    "            'best_sentence': article_sentences[trlm_fo_best_idx],\n",
    "            'best_score': trlm_fo_scores[trlm_fo_best_idx]\n",
    "        },\n",
    "        'trlm_ba': {\n",
    "            'scores': trlm_ba_scores,\n",
    "            'best_sentence': article_sentences[trlm_ba_best_idx],\n",
    "            'best_score': trlm_ba_scores[trlm_ba_best_idx]\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_model_scores(fo_model, fo_tokenizer, ba_model, ba_tokenizer, \n",
    "                          article_sentences, highlight, device='cpu'):\n",
    "    \"\"\"\n",
    "    A simplified, more direct implementation to debug the issue.\n",
    "    \"\"\"\n",
    "    # Forward baseline scoring (query → response)\n",
    "    fw_scores = []\n",
    "    for sentence in article_sentences:\n",
    "        # Standard way: how likely is the highlight given the sentence\n",
    "        prompt = f\"{sentence} is summarized by: {highlight}\"\n",
    "        inputs = fo_tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "        \n",
    "        with t.no_grad():\n",
    "            outputs = fo_model(**inputs, labels=inputs[\"input_ids\"])\n",
    "            fw_scores.append(outputs.loss.item())\n",
    "    \n",
    "    # TRLM-Fo scoring (response → query using forward model)\n",
    "    trlm_fo_scores = []\n",
    "    for sentence in article_sentences:\n",
    "        # Reverse direction: how likely is the sentence given the highlight\n",
    "        prompt = f\"{highlight} is a summary of: {sentence}\"\n",
    "        inputs = fo_tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "        \n",
    "        with t.no_grad():\n",
    "            outputs = fo_model(**inputs, labels=inputs[\"input_ids\"])\n",
    "            trlm_fo_scores.append(outputs.loss.item())\n",
    "    \n",
    "    # TRLM-Ba scoring (response → query using backward model)\n",
    "    trlm_ba_scores = []\n",
    "    for sentence in article_sentences:\n",
    "        # For backward model: reverse the entire prompt\n",
    "        prompt = f\"{sentence} is summarized by: {highlight}\"\n",
    "        tokens = ba_tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device)\n",
    "        reversed_tokens = t.flip(tokens, dims=[1])\n",
    "        \n",
    "        with t.no_grad():\n",
    "            outputs = ba_model(reversed_tokens, labels=reversed_tokens)\n",
    "            trlm_ba_scores.append(outputs.loss.item())\n",
    "    \n",
    "    # Find best match for each model\n",
    "    fw_best_idx = np.argmin(fw_scores)\n",
    "    trlm_fo_best_idx = np.argmin(trlm_fo_scores)\n",
    "    trlm_ba_best_idx = np.argmin(trlm_ba_scores)\n",
    "    \n",
    "    # Print some debug info\n",
    "    print(\"\\nDEBUG INFO:\")\n",
    "    print(f\"Forward scores (min: {min(fw_scores):.4f}, idx: {fw_best_idx})\")\n",
    "    print(f\"TRLM-Fo scores (min: {min(trlm_fo_scores):.4f}, idx: {trlm_fo_best_idx})\")\n",
    "    print(f\"TRLM-Ba scores (min: {min(trlm_ba_scores):.4f}, idx: {trlm_ba_best_idx})\")\n",
    "    \n",
    "    return {\n",
    "        'forward': {\n",
    "            'scores': fw_scores,\n",
    "            'best_sentence': article_sentences[fw_best_idx],\n",
    "            'best_score': fw_scores[fw_best_idx]\n",
    "        },\n",
    "        'trlm_fo': {\n",
    "            'scores': trlm_fo_scores,\n",
    "            'best_sentence': article_sentences[trlm_fo_best_idx],\n",
    "            'best_score': trlm_fo_scores[trlm_fo_best_idx]\n",
    "        },\n",
    "        'trlm_ba': {\n",
    "            'scores': trlm_ba_scores,\n",
    "            'best_sentence': article_sentences[trlm_ba_best_idx],\n",
    "            'best_score': trlm_ba_scores[trlm_ba_best_idx]\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_evaluation(num_samples=10):\n",
    "    # Setup part remains the same\n",
    "    if t.cuda.is_available(): \n",
    "        device = 'cuda' \n",
    "    elif t.backends.mps.is_available():\n",
    "        device = 'mps'\n",
    "    else:\n",
    "        device = 'cpu'\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    fo_model, fo_tokenizer, ba_model, ba_tokenizer = load_models(device)\n",
    "    dataset = load_cnn_dataset(num_samples)\n",
    "    \n",
    "    print(f\"Dataset type: {type(dataset)}\")\n",
    "    print(f\"Dataset keys: {dataset.keys()}\")\n",
    "    \n",
    "    # Results list to store all evaluation results\n",
    "    results = []\n",
    "    \n",
    "    # Process each example\n",
    "    num_examples = len(dataset['article']) if 'article' in dataset else 0\n",
    "    print(f\"Processing {num_examples} examples\")\n",
    "    \n",
    "    for idx in tqdm(range(num_examples)):\n",
    "        try:\n",
    "            # Prepare the example\n",
    "            example = {\n",
    "                'article': dataset['article'][idx],\n",
    "                'highlights': dataset['highlights'][idx],\n",
    "                'id': dataset['id'][idx] if 'id' in dataset else f\"example_{idx}\"\n",
    "            }\n",
    "            \n",
    "            # Print info\n",
    "            print(f\"\\n--- Example {idx+1} ---\")\n",
    "            print(f\"Article (truncated): {example['article'][:150]}...\")\n",
    "            print(f\"Highlight: {example['highlights']}\")\n",
    "            \n",
    "            # Preprocess\n",
    "            processed = preprocess_text(example)\n",
    "            article_sentences = processed['article_sentences']\n",
    "            \n",
    "            # Skip if article is too short\n",
    "            if len(article_sentences) < 3:\n",
    "                print(\"Article too short, skipping\")\n",
    "                continue\n",
    "                \n",
    "            # Evaluate on first highlight sentence (if available)\n",
    "            if processed['highlight_sentences']:\n",
    "                highlight = processed['highlight_sentences'][0]\n",
    "                \n",
    "                # Get scores for all models\n",
    "                model_results = calculate_model_scores(\n",
    "                    fo_model, fo_tokenizer, ba_model, ba_tokenizer,\n",
    "                    article_sentences, highlight, device\n",
    "                )\n",
    "                \n",
    "                # Calculate metrics\n",
    "                fw_metrics = calculate_metrics(\n",
    "                    model_results['forward']['best_sentence'], \n",
    "                    processed['highlight_sentences']\n",
    "                )\n",
    "                \n",
    "                trlm_fo_metrics = calculate_metrics(\n",
    "                    model_results['trlm_fo']['best_sentence'], \n",
    "                    processed['highlight_sentences']\n",
    "                )\n",
    "                \n",
    "                trlm_ba_metrics = calculate_metrics(\n",
    "                    model_results['trlm_ba']['best_sentence'], \n",
    "                    processed['highlight_sentences']\n",
    "                )\n",
    "                \n",
    "                # Store results\n",
    "                result = {\n",
    "                    'example_id': example['id'],\n",
    "                    'highlight': highlight,\n",
    "                    'forward_sentence': model_results['forward']['best_sentence'],\n",
    "                    'trlm_fo_sentence': model_results['trlm_fo']['best_sentence'],\n",
    "                    'trlm_ba_sentence': model_results['trlm_ba']['best_sentence'],\n",
    "                    'forward_score': model_results['forward']['best_score'],\n",
    "                    'trlm_fo_score': model_results['trlm_fo']['best_score'],\n",
    "                    'trlm_ba_score': model_results['trlm_ba']['best_score']\n",
    "                }\n",
    "                \n",
    "                # Add all metrics\n",
    "                for metric, value in fw_metrics.items():\n",
    "                    result[f'forward_{metric}'] = value\n",
    "                \n",
    "                for metric, value in trlm_fo_metrics.items():\n",
    "                    result[f'trlm_fo_{metric}'] = value\n",
    "                    \n",
    "                for metric, value in trlm_ba_metrics.items():\n",
    "                    result[f'trlm_ba_{metric}'] = value\n",
    "                \n",
    "                results.append(result)\n",
    "                \n",
    "                # Print metrics\n",
    "                print(f\"Forward: {model_results['forward']['best_sentence']}\")\n",
    "                print(f\"TRLM-Fo: {model_results['trlm_fo']['best_sentence']}\")\n",
    "                print(f\"TRLM-Ba: {model_results['trlm_ba']['best_sentence']}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing example {idx}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_detailed_dataframe(results):\n",
    "    \"\"\"\n",
    "    Create a simplified DataFrame focusing only on the loss/score comparisons.\n",
    "    \"\"\"\n",
    "    if not results:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Convert results to DataFrame\n",
    "    df = pd.DataFrame(results)\n",
    "    \n",
    "    # Create a new DataFrame with multi-index columns\n",
    "    example_cols = ['example_id', 'highlight']\n",
    "    model_names = ['forward', 'trlm_fo', 'trlm_ba']\n",
    "    \n",
    "    # Create multi-index column list\n",
    "    columns = []\n",
    "    for col in example_cols:\n",
    "        columns.append((col, ''))\n",
    "    \n",
    "    # Add sentences and scores columns\n",
    "    for model in model_names:\n",
    "        # Add sentence column\n",
    "        columns.append((model, 'sentence'))\n",
    "        # Add score column\n",
    "        columns.append((model, 'score'))\n",
    "    \n",
    "    # Create multi-index DataFrame\n",
    "    multi_df = pd.DataFrame(index=df.index)\n",
    "    \n",
    "    # Add example columns\n",
    "    for col in example_cols:\n",
    "        multi_df[(col, '')] = df[col]\n",
    "    \n",
    "    # Add sentence and score columns\n",
    "    for model in model_names:\n",
    "        # Add sentence\n",
    "        multi_df[(model, 'sentence')] = df[f'{model}_sentence']\n",
    "        # Add score\n",
    "        multi_df[(model, 'score')] = df[f'{model}_score']\n",
    "    \n",
    "    # Set column multi-index\n",
    "    multi_df.columns = pd.MultiIndex.from_tuples(columns)\n",
    "    \n",
    "    return multi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "def create_summary_dataframe(results):\n",
    "    \"\"\"\n",
    "    Create a summary DataFrame with models as rows and metrics as columns.\n",
    "    \"\"\"\n",
    "    if not results:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Convert to DataFrame first\n",
    "    df = pd.DataFrame(results)\n",
    "    \n",
    "    # Models we're comparing\n",
    "    models = ['forward', 'trlm_fo', 'trlm_ba']\n",
    "    \n",
    "    # Metrics we want to summarize\n",
    "    metrics = [\n",
    "        'score',\n",
    "        'perplexity',\n",
    "        'tfidf_similarity',\n",
    "        'embedding_similarity', \n",
    "        'rouge1',\n",
    "        'rougeL',\n",
    "        'bleu'\n",
    "    ]\n",
    "    \n",
    "    # Create the summary DataFrame\n",
    "    summary_data = {}\n",
    "    \n",
    "    for metric in metrics:\n",
    "        for model in models:\n",
    "            col_name = f'{model}_{metric}'\n",
    "            if col_name in df.columns:\n",
    "                if metric not in summary_data:\n",
    "                    summary_data[metric] = {}\n",
    "                summary_data[metric][model] = df[col_name].mean()\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    \n",
    "    return summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Dataset loaded successfully\n",
      "Example dataset item: {'article': 'LONDON, England (Reuters) -- Harry Potter star Daniel Radcliffe gains access to a reported £20 million ($41.1 million) fortune as he turns 18 on Monday, but he insists the money won\\'t cast a spell on him. Daniel Radcliffe as Harry Potter in \"Harry Potter and the Order of the Phoenix\" To the disappointment of gossip columnists around the world, the young actor says he has no plans to fritter his cash away on fast cars, drink and celebrity parties. \"I don\\'t plan to be one of those people who, as soon as they turn 18, suddenly buy themselves a massive sports car collection or something similar,\" he told an Australian interviewer earlier this month. \"I don\\'t think I\\'ll be particularly extravagant. \"The things I like buying are things that cost about 10 pounds -- books and CDs and DVDs.\" At 18, Radcliffe will be able to gamble in a casino, buy a drink in a pub or see the horror film \"Hostel: Part II,\" currently six places below his number one movie on the UK box office chart. Details of how he\\'ll mark his landmark birthday are under wraps. His agent and publicist had no comment on his plans. \"I\\'ll definitely have some sort of party,\" he said in an interview. \"Hopefully none of you will be reading about it.\" Radcliffe\\'s earnings from the first five Potter films have been held in a trust fund which he has not been able to touch. Despite his growing fame and riches, the actor says he is keeping his feet firmly on the ground. \"People are always looking to say \\'kid star goes off the rails,\\'\" he told reporters last month. \"But I try very hard not to go that way because it would be too easy for them.\" His latest outing as the boy wizard in \"Harry Potter and the Order of the Phoenix\" is breaking records on both sides of the Atlantic and he will reprise the role in the last two films.  Watch I-Reporter give her review of Potter\\'s latest » . There is life beyond Potter, however. The Londoner has filmed a TV movie called \"My Boy Jack,\" about author Rudyard Kipling and his son, due for release later this year. He will also appear in \"December Boys,\" an Australian film about four boys who escape an orphanage. Earlier this year, he made his stage debut playing a tortured teenager in Peter Shaffer\\'s \"Equus.\" Meanwhile, he is braced for even closer media scrutiny now that he\\'s legally an adult: \"I just think I\\'m going to be more sort of fair game,\" he told Reuters. E-mail to a friend . Copyright 2007 Reuters. All rights reserved.This material may not be published, broadcast, rewritten, or redistributed.', 'highlights': \"Harry Potter star Daniel Radcliffe gets £20M fortune as he turns 18 Monday .\\nYoung actor says he has no plans to fritter his cash away .\\nRadcliffe's earnings from first five Potter films have been held in trust fund .\", 'id': '42c027e4ff9730fbb3de84c1af0d2c506e41c3e4'}\n",
      "Dataset type: <class 'dict'>\n",
      "Dataset keys: dict_keys(['article', 'highlights', 'id'])\n",
      "Processing 5 examples\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f021053501cc4ce98d3c5e544cc31deb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Example 1 ---\n",
      "Article (truncated): LONDON, England (Reuters) -- Harry Potter star Daniel Radcliffe gains access to a reported £20 million ($41.1 million) fortune as he turns 18 on Monda...\n",
      "Highlight: Harry Potter star Daniel Radcliffe gets £20M fortune as he turns 18 Monday .\n",
      "Young actor says he has no plans to fritter his cash away .\n",
      "Radcliffe's earnings from first five Potter films have been held in trust fund .\n",
      "\n",
      "DEBUG INFO:\n",
      "Forward scores (min: 3.3123, idx: 0)\n",
      "TRLM-Fo scores (min: 3.4389, idx: 0)\n",
      "TRLM-Ba scores (min: 3.6711, idx: 0)\n",
      "Forward: LONDON, England (Reuters) -- Harry Potter star Daniel Radcliffe gains access to a reported £20 million ($41.1 million) fortune as he turns 18 on Monday, but he insists the money won't cast a spell on him.\n",
      "TRLM-Fo: LONDON, England (Reuters) -- Harry Potter star Daniel Radcliffe gains access to a reported £20 million ($41.1 million) fortune as he turns 18 on Monday, but he insists the money won't cast a spell on him.\n",
      "TRLM-Ba: LONDON, England (Reuters) -- Harry Potter star Daniel Radcliffe gains access to a reported £20 million ($41.1 million) fortune as he turns 18 on Monday, but he insists the money won't cast a spell on him.\n",
      "\n",
      "--- Example 2 ---\n",
      "Article (truncated): Editor's note: In our Behind the Scenes series, CNN correspondents share their experiences in covering news and analyze the stories behind the events....\n",
      "Highlight: Mentally ill inmates in Miami are housed on the \"forgotten floor\"\n",
      "Judge Steven Leifman says most are there as a result of \"avoidable felonies\"\n",
      "While CNN tours facility, patient shouts: \"I am the son of the president\"\n",
      "Leifman says the system is unjust and he's fighting for change .\n",
      "\n",
      "DEBUG INFO:\n",
      "Forward scores (min: 3.8353, idx: 39)\n",
      "TRLM-Fo scores (min: 3.8541, idx: 37)\n",
      "TRLM-Ba scores (min: 3.8356, idx: 37)\n",
      "Forward: Starting in 2008, many inmates who would otherwise have been brought to the \"forgotten floor\"  will instead be sent to a new mental health facility -- the first step on a journey toward long-term treatment, not just punishment.\n",
      "TRLM-Fo: Leifman says in 1955 there were more than half a million people in state mental hospitals, and today that number has been reduced 90 percent, and 40,000 to 50,000 people are in mental hospitals.\n",
      "TRLM-Ba: Leifman says in 1955 there were more than half a million people in state mental hospitals, and today that number has been reduced 90 percent, and 40,000 to 50,000 people are in mental hospitals.\n",
      "\n",
      "--- Example 3 ---\n",
      "Article (truncated): MINNEAPOLIS, Minnesota (CNN) -- Drivers who were on the Minneapolis bridge when it collapsed told harrowing tales of survival. \"The whole bridge from ...\n",
      "Highlight: NEW: \"I thought I was going to die,\" driver says .\n",
      "Man says pickup truck was folded in half; he just has cut on face .\n",
      "Driver: \"I probably had a 30-, 35-foot free fall\"\n",
      "Minnesota bridge collapsed during rush hour Wednesday .\n",
      "\n",
      "DEBUG INFO:\n",
      "Forward scores (min: 3.3470, idx: 46)\n",
      "TRLM-Fo scores (min: 3.0838, idx: 46)\n",
      "TRLM-Ba scores (min: 3.3578, idx: 46)\n",
      "Forward: \"I knew the deck was going down, there was no question about it, and I thought I was going to die,\" he said.\n",
      "TRLM-Fo: \"I knew the deck was going down, there was no question about it, and I thought I was going to die,\" he said.\n",
      "TRLM-Ba: \"I knew the deck was going down, there was no question about it, and I thought I was going to die,\" he said.\n",
      "\n",
      "--- Example 4 ---\n",
      "Article (truncated): WASHINGTON (CNN) -- Doctors removed five small polyps from President Bush's colon on Saturday, and \"none appeared worrisome,\" a White House spokesman ...\n",
      "Highlight: Five small polyps found during procedure; \"none worrisome,\" spokesman says .\n",
      "President reclaims powers transferred to vice president .\n",
      "Bush undergoes routine colonoscopy at Camp David .\n",
      "\n",
      "DEBUG INFO:\n",
      "Forward scores (min: 4.0825, idx: 16)\n",
      "TRLM-Fo scores (min: 3.9423, idx: 13)\n",
      "TRLM-Ba scores (min: 3.8439, idx: 13)\n",
      "Forward: A colonoscopy is the most sensitive test for colon cancer, rectal cancer and polyps, small clumps of cells that can become cancerous, according to the Mayo Clinic.\n",
      "TRLM-Fo: The procedure was supervised by Dr. Richard Tubb, Bush's physician, and conducted by a multidisciplinary team from the National Naval Medical Center in Bethesda, Maryland, the White House said.\n",
      "TRLM-Ba: The procedure was supervised by Dr. Richard Tubb, Bush's physician, and conducted by a multidisciplinary team from the National Naval Medical Center in Bethesda, Maryland, the White House said.\n",
      "\n",
      "--- Example 5 ---\n",
      "Article (truncated): (CNN)  -- The National Football League has indefinitely suspended Atlanta Falcons quarterback Michael Vick without pay, officials with the league said...\n",
      "Highlight: NEW: NFL chief, Atlanta Falcons owner critical of Michael Vick's conduct .\n",
      "NFL suspends Falcons quarterback indefinitely without pay .\n",
      "Vick admits funding dogfighting operation but says he did not gamble .\n",
      "Vick due in federal court Monday; future in NFL remains uncertain .\n",
      "\n",
      "DEBUG INFO:\n",
      "Forward scores (min: 3.6360, idx: 36)\n",
      "TRLM-Fo scores (min: 3.5380, idx: 13)\n",
      "TRLM-Ba scores (min: 3.5897, idx: 13)\n",
      "Forward: \"Such costs may include, but are not limited to, all costs associated with the care of the dogs involved in that case, including if necessary, the long-term care and/or the humane euthanasia of some or all of those animals.\"\n",
      "TRLM-Fo: The charge is punishable by up to five years in prison, a $250,000 fine, \"full restitution, a special assessment and 3 years of supervised release,\" the plea deal said.\n",
      "TRLM-Ba: The charge is punishable by up to five years in prison, a $250,000 fine, \"full restitution, a special assessment and 3 years of supervised release,\" the plea deal said.\n"
     ]
    }
   ],
   "source": [
    "results = run_evaluation(num_samples=5)   \n",
    " \n",
    "# Create detailed DataFrame\n",
    "detailed_df = create_detailed_dataframe(results)\n",
    "\n",
    "# Create summary DataFrame\n",
    "summary_df = create_summary_dataframe(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>example_id</th>\n",
       "      <th>highlight</th>\n",
       "      <th colspan=\"2\" halign=\"left\">forward</th>\n",
       "      <th colspan=\"2\" halign=\"left\">trlm_fo</th>\n",
       "      <th colspan=\"2\" halign=\"left\">trlm_ba</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>score</th>\n",
       "      <th>sentence</th>\n",
       "      <th>score</th>\n",
       "      <th>sentence</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42c027e4ff9730fbb3de84c1af0d2c506e41c3e4</td>\n",
       "      <td>Harry Potter star Daniel Radcliffe gets £20M f...</td>\n",
       "      <td>LONDON, England (Reuters) -- Harry Potter star...</td>\n",
       "      <td>3.312327</td>\n",
       "      <td>LONDON, England (Reuters) -- Harry Potter star...</td>\n",
       "      <td>3.438889</td>\n",
       "      <td>LONDON, England (Reuters) -- Harry Potter star...</td>\n",
       "      <td>3.671095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ee8871b15c50d0db17b0179a6d2beab35065f1e9</td>\n",
       "      <td>Mentally ill inmates in Miami are housed on th...</td>\n",
       "      <td>Starting in 2008, many inmates who would other...</td>\n",
       "      <td>3.835283</td>\n",
       "      <td>Leifman says in 1955 there were more than half...</td>\n",
       "      <td>3.854144</td>\n",
       "      <td>Leifman says in 1955 there were more than half...</td>\n",
       "      <td>3.835589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>06352019a19ae31e527f37f7571c6dd7f0c5da37</td>\n",
       "      <td>NEW: \"I thought I was going to die,\" driver sa...</td>\n",
       "      <td>\"I knew the deck was going down, there was no ...</td>\n",
       "      <td>3.347004</td>\n",
       "      <td>\"I knew the deck was going down, there was no ...</td>\n",
       "      <td>3.083808</td>\n",
       "      <td>\"I knew the deck was going down, there was no ...</td>\n",
       "      <td>3.357843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24521a2abb2e1f5e34e6824e0f9e56904a2b0e88</td>\n",
       "      <td>Five small polyps found during procedure; \"non...</td>\n",
       "      <td>A colonoscopy is the most sensitive test for c...</td>\n",
       "      <td>4.082534</td>\n",
       "      <td>The procedure was supervised by Dr. Richard Tu...</td>\n",
       "      <td>3.942272</td>\n",
       "      <td>The procedure was supervised by Dr. Richard Tu...</td>\n",
       "      <td>3.843853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7fe70cc8b12fab2d0a258fababf7d9c6b5e1262a</td>\n",
       "      <td>NEW: NFL chief, Atlanta Falcons owner critical...</td>\n",
       "      <td>\"Such costs may include, but are not limited t...</td>\n",
       "      <td>3.635967</td>\n",
       "      <td>The charge is punishable by up to five years i...</td>\n",
       "      <td>3.538003</td>\n",
       "      <td>The charge is punishable by up to five years i...</td>\n",
       "      <td>3.589679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 example_id  \\\n",
       "                                              \n",
       "0  42c027e4ff9730fbb3de84c1af0d2c506e41c3e4   \n",
       "1  ee8871b15c50d0db17b0179a6d2beab35065f1e9   \n",
       "2  06352019a19ae31e527f37f7571c6dd7f0c5da37   \n",
       "3  24521a2abb2e1f5e34e6824e0f9e56904a2b0e88   \n",
       "4  7fe70cc8b12fab2d0a258fababf7d9c6b5e1262a   \n",
       "\n",
       "                                           highlight  \\\n",
       "                                                       \n",
       "0  Harry Potter star Daniel Radcliffe gets £20M f...   \n",
       "1  Mentally ill inmates in Miami are housed on th...   \n",
       "2  NEW: \"I thought I was going to die,\" driver sa...   \n",
       "3  Five small polyps found during procedure; \"non...   \n",
       "4  NEW: NFL chief, Atlanta Falcons owner critical...   \n",
       "\n",
       "                                             forward            \\\n",
       "                                            sentence     score   \n",
       "0  LONDON, England (Reuters) -- Harry Potter star...  3.312327   \n",
       "1  Starting in 2008, many inmates who would other...  3.835283   \n",
       "2  \"I knew the deck was going down, there was no ...  3.347004   \n",
       "3  A colonoscopy is the most sensitive test for c...  4.082534   \n",
       "4  \"Such costs may include, but are not limited t...  3.635967   \n",
       "\n",
       "                                             trlm_fo            \\\n",
       "                                            sentence     score   \n",
       "0  LONDON, England (Reuters) -- Harry Potter star...  3.438889   \n",
       "1  Leifman says in 1955 there were more than half...  3.854144   \n",
       "2  \"I knew the deck was going down, there was no ...  3.083808   \n",
       "3  The procedure was supervised by Dr. Richard Tu...  3.942272   \n",
       "4  The charge is punishable by up to five years i...  3.538003   \n",
       "\n",
       "                                             trlm_ba            \n",
       "                                            sentence     score  \n",
       "0  LONDON, England (Reuters) -- Harry Potter star...  3.671095  \n",
       "1  Leifman says in 1955 there were more than half...  3.835589  \n",
       "2  \"I knew the deck was going down, there was no ...  3.357843  \n",
       "3  The procedure was supervised by Dr. Richard Tu...  3.843853  \n",
       "4  The charge is punishable by up to five years i...  3.589679  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detailed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>tfidf_similarity</th>\n",
       "      <th>embedding_similarity</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>bleu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>forward</th>\n",
       "      <td>3.642623</td>\n",
       "      <td>0.231524</td>\n",
       "      <td>0.529002</td>\n",
       "      <td>0.255832</td>\n",
       "      <td>0.232182</td>\n",
       "      <td>0.107367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trlm_fo</th>\n",
       "      <td>3.571423</td>\n",
       "      <td>0.214766</td>\n",
       "      <td>0.511483</td>\n",
       "      <td>0.231062</td>\n",
       "      <td>0.216945</td>\n",
       "      <td>0.094781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trlm_ba</th>\n",
       "      <td>3.659612</td>\n",
       "      <td>0.214766</td>\n",
       "      <td>0.511483</td>\n",
       "      <td>0.231062</td>\n",
       "      <td>0.216945</td>\n",
       "      <td>0.094781</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            score  tfidf_similarity  embedding_similarity    rouge1    rougeL  \\\n",
       "forward  3.642623          0.231524              0.529002  0.255832  0.232182   \n",
       "trlm_fo  3.571423          0.214766              0.511483  0.231062  0.216945   \n",
       "trlm_ba  3.659612          0.214766              0.511483  0.231062  0.216945   \n",
       "\n",
       "             bleu  \n",
       "forward  0.107367  \n",
       "trlm_fo  0.094781  \n",
       "trlm_ba  0.094781  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
